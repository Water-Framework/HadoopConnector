package it.water.connectors.hadoop.service;

import it.water.connectors.hadoop.api.HadoopConnectorSystemApi;
import it.water.connectors.hadoop.api.options.HadoopOptions;
import it.water.core.interceptors.annotations.FrameworkComponent;
import it.water.core.interceptors.annotations.Inject;
import it.water.core.model.exceptions.WaterRuntimeException;
import it.water.core.service.BaseSystemServiceImpl;
import lombok.Setter;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.LocalFileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.hdfs.DistributedFileSystem;
import org.apache.hadoop.io.IOUtils;

import java.io.*;


/**
 * @Generated by Water Generator
 * System Service Api Class for HadoopConnector entity.
 */
@FrameworkComponent
public class HadoopConnectorSystemServiceImpl extends BaseSystemServiceImpl implements HadoopConnectorSystemApi {

    @Inject
    @Setter
    private HadoopOptions hadoopOptions;
    private Configuration configuration;

    @Override
    public boolean exists(String path) throws IOException {
        FileSystem fileSystem = getHadoopFileSystem();
        Path p = new Path(path);
        return fileSystem.exists(p);
    }

    @Override
    public void upload(File file, String path, boolean deleteSource) throws IOException {
        FileSystem fileSystem = getHadoopFileSystem();
        if (exists(path))
            throw new IllegalStateException("path already exists");
        Path p = new Path(path);
        try (OutputStream os = fileSystem.create(p)) {
            InputStream is = new BufferedInputStream(new FileInputStream(file));
            IOUtils.copyBytes(is, os, configuration); // copy content to file which has been created previously
        }
    }

    public InputStream download(String pathStr) throws IOException {
        FileSystem fileSystem = getHadoopFileSystem();
        Path path = new Path(pathStr);
        if (fileSystem.exists(path)) {
            return fileSystem.open(path);
        }
        throw new IllegalStateException("path does not exist");
    }

    public OutputStream appendToFile(String pathStr) throws IOException {
        FileSystem fileSystem = getHadoopFileSystem();
        Path path = new Path(pathStr);
        if (!fileSystem.exists(path)) {
            return fileSystem.create(path);
        } else {
            return fileSystem.append(path);
        }
    }

    public void createFolder(String path) throws IOException {
        FileSystem fileSystem = getHadoopFileSystem();
        if (exists(path))
            throw new IllegalStateException("path already exists");
        Path p = new Path(path);
        fileSystem.create(p);
    }

    @Override
    public void deleteFile(String path) throws IOException {
        FileSystem fileSystem = getHadoopFileSystem();
        fileSystem.delete(new Path(path), false);
    }

    @Override
    public void deleteFolder(String path) throws IOException {
        FileSystem fileSystem = getHadoopFileSystem();
        if (fileSystem != null)
            fileSystem.delete(new Path(path), true);
        else
            getLog().error("Cannot delete folder: file system is null");
    }

    /**
     * @return Hadoop FileSystem client from specified configuration
     */
    private FileSystem getHadoopFileSystem() {
        // Set bundle class loader in order to find classes defined inside this bundle:
        // this is required for Configuration to load DistributedFileSystem class
        ClassLoader externalClassLoader = Thread.currentThread().getContextClassLoader();
        ClassLoader thisClassLoader = this.getClass().getClassLoader();
        Thread.currentThread().setContextClassLoader(thisClassLoader);
        try {
            if (configuration == null) {
                configuration = new Configuration();
                configuration.set("fs.hdfs.impl", DistributedFileSystem.class.getName());
                configuration.set("fs.file.impl", LocalFileSystem.class.getName());
                configuration.set("fs.defaultFS", hadoopOptions.getHadoopUrl());
                // Using always hostnames
                configuration.set("dfs.client.use.datanode.hostname", "true");
                configuration.set("hadoop.security.token.service.use_ip", "false");
            }
            return FileSystem.get(configuration);
        } catch (Exception t) {
            getLog().error(t.getMessage(), t);
        } finally {
            Thread.currentThread().setContextClassLoader(externalClassLoader);
        }
        throw new WaterRuntimeException("Cannot find HDFS filesystem");
    }
}